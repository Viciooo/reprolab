{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dc593a-dd12-420e-9a38-c26fc1b68e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 00:11:15 - INFO - Starting experiment process\n",
      "2025-06-21 00:11:15 - INFO - Step 1: Saving all notebooks\n",
      "2025-06-21 00:11:15 - INFO - Attempting to save all Jupyter notebooks...\n",
      "2025-06-21 00:11:16 - INFO - ipylab save command executed successfully\n",
      "2025-06-21 00:11:16 - INFO - nbformat processing completed for 3 notebooks\n",
      "2025-06-21 00:11:17 - INFO - Jupyter save commands executed successfully\n",
      "2025-06-21 00:11:17 - INFO - All save methods completed\n",
      "2025-06-21 00:11:17 - INFO - Step 2: Determining next tag name\n",
      "2025-06-21 00:11:17 - INFO - Determining next tag name\n",
      "2025-06-21 00:11:17 - INFO - Fetching all tags from remote repositories\n",
      "2025-06-21 00:11:19 - INFO - Found 9 tags: ['v1.0.0', 'v1.1.0', 'v1.2.0', 'v1.3.0', 'v1.4.0', 'v1.5.0', 'v1.6.0', 'v1.7.0', 'v1.8.0']\n",
      "2025-06-21 00:11:19 - INFO - Latest tag: v1.8.0, next tag: v1.9.0\n",
      "2025-06-21 00:11:19 - INFO - Step 3: Committing with message: 'Project state before running experiment v1.9.0'\n",
      "2025-06-21 00:11:19 - INFO - Starting commit process with message: 'Project state before running experiment v1.9.0'\n",
      "2025-06-21 00:11:19 - INFO - Adding all files to staging area\n",
      "2025-06-21 00:11:19 - INFO - Starting process to add all files to git staging area\n",
      "2025-06-21 00:11:19 - INFO - Checking git status for all files\n",
      "2025-06-21 00:11:19 - INFO - Found 4 untracked files\n",
      "2025-06-21 00:11:19 - INFO - Found 0 modified files\n",
      "2025-06-21 00:11:19 - INFO - Found 0 deleted files\n",
      "2025-06-21 00:11:19 - INFO - Adding all files to git staging\n",
      "2025-06-21 00:11:19 - INFO - Successfully added all files to staging\n",
      "2025-06-21 00:11:19 - INFO - Checking for staged changes\n",
      "2025-06-21 00:11:19 - INFO - Staged 8 files for commit\n",
      "2025-06-21 00:11:19 - INFO - Creating commit with message: 'Project state before running experiment v1.9.0'\n",
      "2025-06-21 00:11:19 - INFO - Successfully committed: Project state before running experiment v1.9.0\n",
      "2025-06-21 00:11:19 - INFO - Successfully started experiment: v1.9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'v1.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reprolab.experiment import start_experiment, end_experiment\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa5815-9602-44e4-91e2-01e1e8f98b7a",
   "metadata": {},
   "source": [
    "# ReproLab Demo\n",
    "\n",
    "Welcome to ReproLab! This extension helps you make your research more reproducible.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Create Experiments**: Automatically save immutable snapshots of your code under `git` tags to preserve the **exact code and outputs**\n",
    "- **Manage Dependencies**: Automatically gather and pin **exact package versions**, so that others can set up your environment with one command\n",
    "- **Cache Data**: Call external API/load manually dataset only once, caching function will handle the rest\n",
    "- **Archive Data**: Caching function can also preserve the compressed data in *AWS S3*, so you always know what data was used and reduce the API calls\n",
    "- **Publishing guide**: The reproducibility checklist & automated generation of reproducability package make publishing to platforms such as Zenodo very easy\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "1. Use the sidebar to view ReproLab features\n",
    "2. Create virtual environment and pin your dependencies, go to reprolab section `Create reproducible environment` \n",
    "3. Create an experiment to save your current state, go to reprolab section `Create experiment`\n",
    "4. Archive your data for long-term storage, go to reprolab section `Demo` and play around with it.\n",
    "5. Publish your work when ready, remember to use reproducability checklist from the section `Reproducibility Checklist`\n",
    "\n",
    "## Example Usage of persistio decorator\n",
    "\n",
    "To cache and archive the datasets you use, both from local files and APIs we developed a simple decorator that put over your function that gets the datasets caches the file both locally and in the cloud so that the dataset you use is archived and the number of calls to external APIs is minimal and you don't need to keep the file around after you run it once.\n",
    "\n",
    "Here is an example using one of NASA open APIs. If you want to test it out yourself, you can copy the code, but you need to provide bucket name and access and secret key in the left-hand panel using the `AWS S3 Configuration` section.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# The two lines below is all that you need to add\n",
    "from reprolab.experiment import persistio\n",
    "@persistio()\n",
    "def get_exoplanets_data_from_nasa():\n",
    "    url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT TOP 10\n",
    "        pl_name AS planet_name,\n",
    "        hostname AS host_star,\n",
    "        pl_orbper AS orbital_period_days,\n",
    "        pl_rade AS planet_radius_earth,\n",
    "        disc_year AS discovery_year\n",
    "    FROM\n",
    "        ps\n",
    "    WHERE\n",
    "        default_flag = 1\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "    return df\n",
    "\n",
    "exoplanets_data = get_exoplanets_data_from_nasa()\n",
    "```\n",
    "\n",
    "If you run this cell twice you will notice from the logs that the second time file was read from the compressed file in the cache. If you were to lose access to local cache (e.g. by pulling the repository using different device) `persistio` would fetch the data from the cloud archive.\n",
    "\n",
    "\n",
    "For more information, visit our [documentation](https://github.com/your-repo/reprolab). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4258fd6c-7289-4a01-aecd-654779bcb9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[persistio] Function: get_exoplanets_data_from_nasa\n",
      "[persistio] Hash: ca840447667cb2059aa83ed68ec9e995\n",
      "âœ… Metadata written to demo.ipynb_persistio_archive.yaml\n",
      "[persistio] Trigger logged for function: get_exoplanets_data_from_nasa\n",
      "[persistio] Attempting to load from local cache...\n",
      "[persistio] Successfully loaded from local cache!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# The two lines below is all that you need to add\n",
    "from reprolab.experiment import persistio\n",
    "@persistio()\n",
    "def get_exoplanets_data_from_nasa():\n",
    "    url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT TOP 10\n",
    "        pl_name AS planet_name,\n",
    "        hostname AS host_star,\n",
    "        pl_orbper AS orbital_period_days,\n",
    "        pl_rade AS planet_radius_earth,\n",
    "        disc_year AS discovery_year\n",
    "    FROM\n",
    "        ps\n",
    "    WHERE\n",
    "        default_flag = 1\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "    return df\n",
    "\n",
    "exoplanets_data = get_exoplanets_data_from_nasa()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abfb8d45-7ae4-46c2-be48-f4663b15c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    }
   ],
   "source": [
    "print('testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9828505-28d5-4d22-b06f-398901e41445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying pip at: /Users/spoton/Documents/master_thesis/poc/reprolab/.my_venv/bin/pip\n",
      "Running command: /Users/spoton/Documents/master_thesis/poc/reprolab/.my_venv/bin/pip freeze\n",
      "Pip dependencies saved to requirements.txt\n",
      "Found 58 packages\n",
      "Not a Conda environment or not activated. Skipping Conda export.\n",
      "\n",
      "To recreate the environment:\n",
      "- For pip: Activate the virtual environment and run: `pip install -r requirements.txt`\n"
     ]
    }
   ],
   "source": [
    "from reprolab.environment import freeze_venv_dependencies\n",
    "freeze_venv_dependencies('.my_venv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c91f9-b2ff-4cbd-915a-c25e8d2baa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 00:12:10 - INFO - Ending experiment process\n",
      "2025-06-21 00:12:10 - INFO - Step 1: Saving all notebooks\n",
      "2025-06-21 00:12:10 - INFO - Attempting to save all Jupyter notebooks...\n",
      "2025-06-21 00:12:10 - INFO - ipylab save command executed successfully\n",
      "2025-06-21 00:12:10 - INFO - nbformat processing completed for 3 notebooks\n"
     ]
    }
   ],
   "source": [
    "end_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c8cae8-99e7-481f-92f3-650a57c46702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1.9.0',\n",
       " 'v1.8.0',\n",
       " 'v1.7.0',\n",
       " 'v1.6.0',\n",
       " 'v1.5.0',\n",
       " 'v1.4.0',\n",
       " 'v1.3.0',\n",
       " 'v1.2.0',\n",
       " 'v1.1.0',\n",
       " 'v1.0.0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reprolab.experiment import list_and_sort_git_tags\n",
    "list_and_sort_git_tags()\n",
    "# Pick your git tag, to download the reproducability package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6607075e-b495-4049-98c1-36e2eecf7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprolab.experiment import download_reproducability_package\n",
    "# download_reproducability_package('v1.7.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.my_venv)",
   "language": "python",
   "name": ".my_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
