{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc7e80a-0118-44e4-8044-6e255a25db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 19:19:21 - INFO - Starting experiment process\n",
      "2025-06-20 19:19:21 - INFO - Step 1: Saving all notebooks\n",
      "2025-06-20 19:19:21 - INFO - Attempting to save all Jupyter notebooks...\n",
      "2025-06-20 19:19:21 - INFO - ipylab save command executed successfully\n",
      "2025-06-20 19:19:21 - WARNING - nbformat not available. Install with: pip install nbformat\n",
      "2025-06-20 19:19:22 - INFO - Jupyter save commands executed successfully\n",
      "2025-06-20 19:19:22 - INFO - All save methods completed\n",
      "2025-06-20 19:19:22 - INFO - Step 2: Determining next tag name\n",
      "2025-06-20 19:19:22 - INFO - Determining next tag name\n",
      "2025-06-20 19:19:22 - INFO - Fetching all tags from remote repositories\n",
      "2025-06-20 19:19:24 - INFO - Found 5 tags: ['v1.0.0', 'v1.1.0', 'v1.2.0', 'v1.3.0', 'v1.4.0']\n",
      "2025-06-20 19:19:24 - INFO - Latest tag: v1.4.0, next tag: v1.5.0\n",
      "2025-06-20 19:19:24 - INFO - Step 3: Committing with message: 'Project state before running experiment v1.5.0'\n",
      "2025-06-20 19:19:24 - INFO - Starting commit process with message: 'Project state before running experiment v1.5.0'\n",
      "2025-06-20 19:19:24 - INFO - Adding all files to staging area\n",
      "2025-06-20 19:19:24 - INFO - Starting process to add all files to git staging area\n",
      "2025-06-20 19:19:24 - INFO - Checking git status for all files\n",
      "2025-06-20 19:19:24 - INFO - Found 3 untracked files\n",
      "2025-06-20 19:19:24 - INFO - Found 0 modified files\n",
      "2025-06-20 19:19:24 - INFO - Found 0 deleted files\n",
      "2025-06-20 19:19:24 - INFO - Adding all files to git staging\n",
      "2025-06-20 19:19:24 - INFO - Successfully added all files to staging\n",
      "2025-06-20 19:19:24 - INFO - Checking for staged changes\n",
      "2025-06-20 19:19:24 - INFO - Staged 3 files for commit\n",
      "2025-06-20 19:19:24 - INFO - Creating commit with message: 'Project state before running experiment v1.5.0'\n",
      "2025-06-20 19:19:24 - INFO - Successfully committed: Project state before running experiment v1.5.0\n",
      "2025-06-20 19:19:24 - INFO - Successfully started experiment: v1.5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'v1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reprolab.experiment import start_experiment, end_experiment\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649096-5fd0-4180-b310-d75cc0c43e47",
   "metadata": {},
   "source": [
    "# ReproLab Demo\n",
    "\n",
    "Welcome to ReproLab! This extension helps you make your research more reproducible.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Create Experiments**: Save immutable snapshots of your code and data\n",
    "- **Track Metrics**: Monitor execution time and resource usage\n",
    "- **Manage Dependencies**: Automatically gather and pin package versions\n",
    "- **Archive Data**: Store your data securely in AWS S3\n",
    "- **Publish**: Share your work on Zenodo\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "1. Use the sidebar to access ReproLab features\n",
    "2. Create an experiment to save your current state\n",
    "3. Track metrics to monitor performance\n",
    "4. Archive your data for long-term storage\n",
    "5. Publish your work when ready\n",
    "\n",
    "## Example Usage of persistio decorator\n",
    "\n",
    "To cache and archive the datasets you use, both from local files and APIs we developed a simple decorator that put over your function that gets the datasets caches the file both locally and in the cloud so that the dataset you use is archived and the number of calls to external APIs is minimal and you don't need to keep the file around after you run it once.\n",
    "\n",
    "Here is an example using one of NASA open APIs. If you want to test it out yourself, you can copy the code, but you need to provide bucket name and access and secret key in the left-hand panel using the `AWS S3 Configuration` section.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# The two lines below is all that you need to add\n",
    "from reprolab.experiment import persistio\n",
    "@persistio()\n",
    "def get_exoplanets_data_from_nasa():\n",
    "    url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT TOP 10\n",
    "        pl_name AS planet_name,\n",
    "        hostname AS host_star,\n",
    "        pl_orbper AS orbital_period_days,\n",
    "        pl_rade AS planet_radius_earth,\n",
    "        disc_year AS discovery_year\n",
    "    FROM\n",
    "        ps\n",
    "    WHERE\n",
    "        default_flag = 1\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "    return df\n",
    "\n",
    "exoplanets_data = get_exoplanets_data_from_nasa()\n",
    "```\n",
    "\n",
    "If you run this cell twice you will notice from the logs that the second time file was read from the compressed file in the cache. If you were to lose access to local cache (e.g. by pulling the repository using different device) `persistio` would fetch the data from the cloud archive.\n",
    "\n",
    "\n",
    "For more information, visit our [documentation](https://github.com/your-repo/reprolab). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612d0978-9c6d-465b-bb68-c70859077167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[persistio] Function: get_exoplanets_data_from_nasa\n",
      "[persistio] Hash: ca840447667cb2059aa83ed68ec9e995\n",
      "[persistio] Attempting to load from local cache...\n",
      "[persistio] Successfully loaded from local cache!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# The two lines below is all that you need to add\n",
    "from reprolab.experiment import persistio\n",
    "@persistio()\n",
    "def get_exoplanets_data_from_nasa():\n",
    "    url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT TOP 10\n",
    "        pl_name AS planet_name,\n",
    "        hostname AS host_star,\n",
    "        pl_orbper AS orbital_period_days,\n",
    "        pl_rade AS planet_radius_earth,\n",
    "        disc_year AS discovery_year\n",
    "    FROM\n",
    "        ps\n",
    "    WHERE\n",
    "        default_flag = 1\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "    return df\n",
    "\n",
    "exoplanets_data = get_exoplanets_data_from_nasa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664ce3c3-5d9f-48a5-8de8-6e43933e7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying pip at: /Users/spoton/Documents/master_thesis/poc/reprolab/my_venv/bin/pip\n",
      "Running command: /Users/spoton/Documents/master_thesis/poc/reprolab/my_venv/bin/pip freeze\n",
      "Pip dependencies saved to requirements.txt\n",
      "Found 49 packages\n",
      "Not a Conda environment or not activated. Skipping Conda export.\n",
      "\n",
      "To recreate the environment:\n",
      "- For pip: Activate the virtual environment and run: `pip install -r requirements.txt`\n"
     ]
    }
   ],
   "source": [
    "from reprolab.environment import freeze_venv_dependencies\n",
    "freeze_venv_dependencies('my_venv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b834df-5a9f-4400-b0b9-edc84caf7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 19:19:24 - INFO - Ending experiment process\n",
      "2025-06-20 19:19:24 - INFO - Step 1: Saving all notebooks\n",
      "2025-06-20 19:19:24 - INFO - Attempting to save all Jupyter notebooks...\n",
      "2025-06-20 19:19:25 - INFO - ipylab save command executed successfully\n",
      "2025-06-20 19:19:25 - WARNING - nbformat not available. Install with: pip install nbformat\n"
     ]
    }
   ],
   "source": [
    "end_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_venv)",
   "language": "python",
   "name": "my_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
